{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b79cc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best POS Path (Tags): [0, 1, 2]\n",
      "Max Probability: 0.0189\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def viterbi_algorithm(observations, states, start_prob, trans_prob, emis_prob):\n",
    "    # Initialize variables\n",
    "    T = len(observations)  # Number of observations (words)\n",
    "    N = len(states)  # Number of states (POS tags)\n",
    "    \n",
    "    # Initialize dynamic programming table and path table\n",
    "    V = np.zeros((N, T))  # Stores maximum probabilities\n",
    "    path = np.zeros((N, T), dtype=int)  # Stores backtracking paths\n",
    "    \n",
    "    # Initialization step\n",
    "    for i in range(N):\n",
    "        V[i, 0] = start_prob[i] * emis_prob[i, observations[0]]\n",
    "        path[i, 0] = 0\n",
    "    \n",
    "    # Recursion step\n",
    "    for t in range(1, T):\n",
    "        for j in range(N):\n",
    "            max_prob = float('-inf')\n",
    "            max_state = 0\n",
    "            for i in range(N):\n",
    "                prob = V[i, t - 1] * trans_prob[i, j] * emis_prob[j, observations[t]]\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    max_state = i\n",
    "            V[j, t] = max_prob\n",
    "            path[j, t] = max_state\n",
    "    \n",
    "    # Termination step\n",
    "    max_prob = float('-inf')\n",
    "    last_state = 0\n",
    "    for i in range(N):\n",
    "        if V[i, T - 1] > max_prob:\n",
    "            max_prob = V[i, T - 1]\n",
    "            last_state = i\n",
    "    \n",
    "    # Backtracking to find the best state sequence\n",
    "    best_path = [last_state]\n",
    "    for t in range(T - 1, 0, -1):\n",
    "        best_path.insert(0, path[best_path[0], t])\n",
    "    \n",
    "    return best_path, max_prob\n",
    "\n",
    "# Example case study in NLP (POS tagging)\n",
    "# Observations (words in a sentence)\n",
    "observations = [0, 1, 2]  # Words encoded as indices: \"dog\", \"barks\", \"loudly\"\n",
    "# Hidden states (POS tags: 0 = noun, 1 = verb, 2 = adverb)\n",
    "states = [0, 1, 2]  \n",
    "\n",
    "# Initial probabilities for each POS tag\n",
    "start_prob = np.array([0.5, 0.3, 0.2])\n",
    "\n",
    "# Transition probabilities between POS tags\n",
    "trans_prob = np.array([[0.4, 0.5, 0.1],  # noun -> noun, verb, adverb\n",
    "                       [0.3, 0.4, 0.3],  # verb -> noun, verb, adverb\n",
    "                       [0.1, 0.3, 0.6]])  # adverb -> noun, verb, adverb\n",
    "\n",
    "# Emission probabilities (word given POS tag)\n",
    "emis_prob = np.array([[0.6, 0.2, 0.2],  # noun -> \"dog\", \"barks\", \"loudly\"\n",
    "                      [0.1, 0.7, 0.2],  # verb -> \"dog\", \"barks\", \"loudly\"\n",
    "                      [0.1, 0.3, 0.6]])  # adverb -> \"dog\", \"barks\", \"loudly\"\n",
    "\n",
    "# Running Viterbi algorithm\n",
    "best_path, max_prob = viterbi_algorithm(observations, states, start_prob, trans_prob, emis_prob)\n",
    "\n",
    "print(\"Best POS Path (Tags):\", best_path)\n",
    "print(\"Max Probability:\", max_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efd8f89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
